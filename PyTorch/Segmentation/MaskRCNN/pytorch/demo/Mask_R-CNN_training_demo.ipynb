{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN Training Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates the steps for training Mask R-CNN models. \n",
    "Mask R-CNN is a convolution-based neural network for the task of object instance segmentation. The original paper describing the model can be found [here](https://arxiv.org/abs/1703.06870). NVIDIA’s Mask R-CNN is an optimized version of [Facebook’s implementation](https://github.com/facebookresearch/maskrcnn-benchmark), leveraging mixed precision arithmetic and tensor cores for faster training times while maintaining comparable accuracy with single precision, i.e. FP32, training.\n",
    "\n",
    "## Notebook  Content\n",
    "1. [Pre-requisite: data](#1)\n",
    "1. [Pre-requisite: container](#2)\n",
    "1. [Training](#3)\n",
    "1. [Testing trained model](#4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## 1. Pre-requisite: data\n",
    "\n",
    "This notebook demonstrates training and validation or the Mask R-CNN model on the [COCO 2014 dataset](http://cocodataset.org/#download). If not already available locally, the following [script](../../download_dataset.sh) in this repository provides a convinient way to download and extract all the necessary data in one go:\n",
    "\n",
    "```\n",
    "./download_dataset.sh <data/dir>\n",
    "```\n",
    "\n",
    "This script can be ran on a Linux host machine. Be mindful of the size of the raw data (~20GB). The script makes use of `wget` and will automatically resume if disrupted. Once downloaded, the scrip invoke `dtrx` to extract the data. The final data directory should look like:\n",
    "\n",
    "```\n",
    "<data/dir>\n",
    "  annotations/\n",
    "    instances_train2014.json\n",
    "    instances_val2014.json\n",
    "  train2014/\n",
    "    COCO_train2014_*.jpg\n",
    "  val2014/\n",
    "    COCO_val2014_*.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## 2. Pre-requisite: container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most convinient way to make use of the NVIDIA Mask R-CNN model is via a docker container, which provides a self-contained, isolated and re-producible environment for all experiments. Follow the quick-start instruction at https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Segmentation/MaskRCNN \n",
    "\n",
    "In short, first clone the repository:\n",
    "\n",
    "```\n",
    "git clone https://github.com/NVIDIA/DeepLearningExamples.git\n",
    "cd DeepLearningExamples/PyTorch/Segmentation/MaskRCNN\n",
    "```\n",
    "\n",
    "Then build the Mask R-CNN PyTorch NGC container.\n",
    "\n",
    "```\n",
    "cd pytorch/\n",
    "bash scripts/docker/build.sh\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
